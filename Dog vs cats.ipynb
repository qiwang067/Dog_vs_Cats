{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "#原始数据集目录\n",
    "original_dataset_dir = 'data/kaggle_original_data'\n",
    "\n",
    "#保存较小数据集的目录\n",
    "base_dir = 'data/cats_and_dogs_small'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "#分别对应划分后的训练、验证和测试的目录\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "if not os.path.exists(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "    \n",
    "# 猫的训练图像目录\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "if not os.path.exists(train_cats_dir):\n",
    "    os.mkdir(train_cats_dir)\n",
    "\n",
    "# 狗的训练图像目录\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "if not os.path.exists(train_dogs_dir):\n",
    "    os.mkdir(train_dogs_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "if not os.path.exists(validation_dir):\n",
    "    os.mkdir(validation_dir)\n",
    "    \n",
    "#猫的验证图像目录\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "if not os.path.exists(validation_cats_dir):\n",
    "    os.mkdir(validation_cats_dir)\n",
    "\n",
    "# 狗的验证图像目录\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "if not os.path.exists(validation_dogs_dir):\n",
    "    os.mkdir(validation_dogs_dir)\n",
    "    \n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "    \n",
    "# 猫的测试图像目录\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "if not os.path.exists(test_cats_dir):\n",
    "    os.mkdir(test_cats_dir)\n",
    "\n",
    "# 狗的测试图像目录\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "if not os.path.exists(test_dogs_dir):\n",
    "    os.mkdir(test_dogs_dir)\n",
    "    \n",
    "# 将前1000张猫的图像复制到 train_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 将接下来 500 张猫的图像复制到 validation_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 将接下来的 500 张猫的图像复制到 test_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 将前 1000 张狗的图像复制到 train_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 将接下来 500 张狗的图像复制到 validation_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 将接下来 500 张狗的图像复制到 test_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#查看每个分组中（训练/验证/测试）中分别包含多少张图像\n",
    "print('total training cat images:',len(os.listdir(train_cats_dir)))\n",
    "print('total training dog images:',len(os.listdir(train_dogs_dir)))\n",
    "print('total validation cat images:',len(os.listdir(validation_cats_dir)))\n",
    "print('total validation dog images:',len(os.listdir(validation_dogs_dir)))\n",
    "print('total test cat images:',len(os.listdir(test_cats_dir)))\n",
    "print('total test dog images:',len(os.listdir(test_dogs_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立模型\n",
    "from keras.applications import VGG16\n",
    "#weghts指定模型初始化的权重检查点，include_top指定模型的最后是否包含密集连接分类器\n",
    "# input_shape是输入到网络中图像张量的形状,这个参数是可选的，如果不传\n",
    "#入这个参数，那么网络能够处理任意形状的输入。\n",
    "conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(150,150,3))\n",
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "#查看特征图的维度随每层的变化\n",
    "model.summary()\n",
    "#冻结直到某一层的所有层\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1'\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = Flase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练模型\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#数据增强\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,    #将图像乘以1/255缩放\n",
    "    rotation_range=40, #图片随机旋转40度\n",
    "    width_shift_range=0.2, #图片在水平方向上平移的距离为图片的总宽度的0.2倍\n",
    "    height_shift_range=0.2, #图片在垂直方向上平移的距离为图片的总高度的0.2倍\n",
    "    shear_range=0.2,  #随机错切变换的角度\n",
    "    zoom_range=0.2,  #图像随机缩放的范围\n",
    "    horizontal_flip=True,\n",
    "    fill_model='nearest') #随机将一半图像翻转\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  #不能增强验证数据\n",
    "\n",
    "#数据预处理\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  #目标目录\n",
    "    target_size = (150,150), #将所有图像的大小调整为150×150\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary')  #因为使用binary_crossentropy损失，所以用二进制标签\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (150,150),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "#编译模型\n",
    "from keras import optimizers\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=e-5),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#利用批量生成器拟合模型\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 100,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 50)\n",
    "\n",
    "#保存模型\n",
    "model.save('cats_and_dogs_small.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#绘制模型在训练集和验证集上的表现\n",
    "import matplotlib.pyplot as plt\n",
    "def smooth_curve(points, factor=0.8):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points\n",
    "\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#在测试集上评估模型\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "print('test acc:', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
